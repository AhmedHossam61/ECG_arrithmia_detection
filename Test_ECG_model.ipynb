{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTqDdKY938mhHixvj+twnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedHossam61/ECG_arrithmia_detection/blob/main/Test_ECG_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubu1GUWlYIND",
        "outputId": "ecd58043-8beb-4cd1-9c54-f2c29d4717d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "zGNcNC0AYIIy",
        "outputId": "d13e1667-1382-4cd2-d1ff-9ce2f5072371"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec0fc8a0-1811-4dbb-9892-f35697808013\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec0fc8a0-1811-4dbb-9892-f35697808013\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"ahmedhossam61\",\"key\":\"898b2acd2a393a179e7a6bc2998923fb\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n"
      ],
      "metadata": {
        "id": "vtq_r0yeYIBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcfaa7c-ce8d-42de-cb8a-f34ed3ad8198"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "JcqZOs7IY0cr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7VOS6OoZZAHq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAQsicsvZGDq",
        "outputId": "31829529-2c05-44b2-d86e-08cff4d6fd5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4 / client 1.6.17)\n",
            "ref                                                                  title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "atharvasoundankar/chocolate-sales                                    Chocolate Sales Data 📊🍫                             63KB  2025-03-07 05:44:03           3582         42  1.0              \n",
            "abdulmalik1518/mobiles-dataset-2025                                  Mobiles Dataset (2025)                              20KB  2025-02-18 06:50:24          10628        191  1.0              \n",
            "adilshamim8/student-performance-on-an-entrance-examination           Student Performance on an Entrance Examination       4KB  2025-03-04 00:09:21           1149         30  1.0              \n",
            "mahmoudelhemaly/students-grading-dataset                             Student Performance & Behavior Dataset             508KB  2025-02-17 17:38:46           7703        124  1.0              \n",
            "ignacioazua/life-expectancy                                          Life Expectancy                                      3KB  2025-03-04 06:16:35           1392         31  1.0              \n",
            "salahuddinahmedshuvo/ecommerce-consumer-behavior-analysis-data       Ecommerce Consumer Behavior Analysis Data           43KB  2025-03-03 13:09:09           1634         23  0.9411765        \n",
            "atharvasoundankar/viral-social-media-trends-and-engagement-analysis  🚀 Viral Social Media Trends & Engagement Analysis  105KB  2025-03-10 04:51:48           1190         22  1.0              \n",
            "rathoddharmendra/post-college-salaries                               U.S Post College Salaries                           12KB  2025-02-19 14:39:29           1261         29  0.8235294        \n",
            "mayuravartak/motogp-riders-2024-performance-dataset                  MotoGP Riders in 2024 Performance Dataset            5KB  2025-03-06 18:48:20            487         25  1.0              \n",
            "vinothkannaece/sales-dataset                                         sales dataset                                       27KB  2025-02-18 05:13:42           6092         81  1.0              \n",
            "ankushpanday2/oral-cancer-prediction-dataset                         Oral Cancer Prediction Dataset                       2MB  2025-03-06 14:13:24            818         27  1.0              \n",
            "anandshaw2001/video-game-sales                                       Video Game Sales                                   381KB  2025-02-23 05:16:04           1174         45  1.0              \n",
            "smayanj/e-commerce-transactions-dataset                              E-Commerce Transactions Dataset                    749KB  2025-03-08 12:20:45            603         43  1.0              \n",
            "amrmaree/student-performance-prediction                              Student Performance Prediction                      11KB  2025-03-03 15:46:10           1513         27  0.9411765        \n",
            "smayanj/netflix-users-database                                       Netflix Users Database                             354KB  2025-03-08 12:08:09            620         36  1.0              \n",
            "atharvasoundankar/futuristic-smart-city-citizen-activity-dataset     📊 Futuristic Smart City Citizen Activity Dataset    23KB  2025-03-06 04:58:22            625         30  1.0              \n",
            "adilshamim8/student-performance-and-learning-style                   Student Performance & Learning Style               148KB  2025-02-12 06:12:07           3349         53  1.0              \n",
            "samikshadalvi/lungs-diseases-dataset                                 Lungs Diseases Dataset                              40KB  2025-02-25 01:51:36           1888         38  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                                Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         173491       1584  0.7058824        \n",
            "sujalsuthar/food-delivery-order-history-data                         Food Delivery Order History Data                     2MB  2025-02-14 02:52:38           1356         28  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMwcc2roZABx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a code to download a kaggle dataset called \"ECG Heartbeat Categorization Dataset\"\n",
        "\n",
        "! kaggle datasets download shayanfazeli/heartbeat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMjeDMC0Y_50",
        "outputId": "5dc2081c-98a0-4b2b-f89c-73df51dae0b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat\n",
            "License(s): unknown\n",
            "heartbeat.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip heartbeat.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1As0JPaWdNST",
        "outputId": "4c2e3d36-8f0c-483d-9843-8bd0ce97c1e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  heartbeat.zip\n",
            "  inflating: mitbih_test.csv         \n",
            "  inflating: mitbih_train.csv        \n",
            "  inflating: ptbdb_abnormal.csv      \n",
            "  inflating: ptbdb_normal.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "L0bsqBow3w3b"
      },
      "outputs": [],
      "source": [
        "X = [1.00000,0.93246,0.73921,0.57223,0.36585,0.17448,0.06191,0.02064,0.02814,\n",
        "    0.03377,0.08443,0.11069,0.13696,0.15385,0.17073,0.17261,0.17824,0.17261,\n",
        "    0.17073,0.16510,0.17073,0.16135,0.16135,0.15009,0.15572,0.14822,0.15385,\n",
        "    0.14822,0.16323,0.16323,0.18386,0.18762,0.21576,0.23077,0.24765,0.25891,\n",
        "    0.27955,0.28143,0.30769,0.31707,0.33959,0.34146,0.36023,0.35835,0.37336,\n",
        "    0.37148,0.37899,0.37336,0.38086,0.37148,0.37711,0.37523,0.37523,0.36210,\n",
        "    0.36773,0.36961,0.37711,0.36585,0.36210,0.34709,0.35272,0.35084,0.34897,\n",
        "    0.30957,0.28518,0.25328,0.24578,0.24015,0.24203,0.24015,0.24390,0.24390,\n",
        "    0.24765,0.24390,0.26079,0.25891,0.26454,0.26642,0.27580,0.26642,0.27392,\n",
        "    0.26454,0.27392,0.25704,0.25328,0.34146,0.50094,0.61538,0.78424,0.93621,\n",
        "    0.99250,0.93246,0.72233,0.51032,0.26829,0.09006,0.01501,0.00000,0.01876,\n",
        "    0.03189,0.08630,0.10694,0.15009,0.16510,0.17261,0.17261,0.17261,0.15947,\n",
        "    0.00000,0.00000 ,1.00000,0.79197,0.16058,0.00365,0.08029,0.10949,0.08394,0.17153,0.18613,0.16788,\n",
        "    0.16423,0.20073,0.27737,0.30657,0.28467,0.27737,0.29927,0.29562,0.28102,\n",
        "    0.30292,0.31752,0.30657,0.31022,0.29197,0.32117,0.32482,0.32117,0.35766,\n",
        "    0.36861,0.36861,0.38686,0.44526,0.48540,0.46715,0.47810,0.52555,0.54015,\n",
        "    0.54745,0.52555,0.48905,0.47080,0.41971,0.37591,0.35401,0.32847,0.29562,\n",
        "    0.26277,0.25547,0.27007,0.25182,0.25547,0.25182,0.26277,0.26277,0.23358,\n",
        "    0.25182,0.26642,0.25182,0.24818,0.25547,0.24453,0.24818,0.25182,0.25182,\n",
        "    0.27737,0.26277,0.26277,0.28467,0.32117,0.26642,0.24453,0.24088,0.24088,\n",
        "    0.25547,0.25912,0.29562,0.27007,0.25547,0.28467,0.24088,0.24818,0.28467,\n",
        "    0.27007,0.25547,0.27372,0.27372,0.28102,0.31022,0.34672,0.40876,0.56934,\n",
        "    0.80292,0.79562,0.28102,0.00000,0.02555,0.09854,0.09124,0.08029,0.17518,\n",
        "    0.19343,0.16423,0.16058,0.19708,0.25547,0.25912,0.26642,0.28832,0.26277,\n",
        "    0.00000,0.00000 , 1.00000,0.79401,0.35768,\n",
        " 0.22659,0.18727,0.17041,0.16105,0.14607,0.14045,0.12921,0.14232,0.13858,\n",
        " 0.14607,0.14045,0.15169,0.14419,0.15543,0.14794,0.15169,0.16105,0.15730,\n",
        " 0.16292,0.16854,0.15918,0.17603,0.17228,0.17790,0.18165,0.19101,0.19101,\n",
        " 0.20599,0.19101,0.19663,0.18727,0.17978,0.17228,0.17416,0.16854,0.17978,\n",
        " 0.17041,0.17416,0.18165,0.18165,0.18539,0.18352,0.18165,0.18165,0.18727,\n",
        " 0.19850,0.20974,0.26404,0.33146,0.43633,0.53933,0.67978,0.77903,0.86330,\n",
        " 0.85206,0.74906,0.67790,0.60674,0.55805,0.53745,0.44757,0.29401,0.11985,\n",
        " 0.07116,0.04682,0.03371,0.02247,0.01498,0.00000,0.00000,0.00000,0.00000,\n",
        " 0.00000,0.00000,0.00000,\n",
        "     1.00000,0.48606,0.53386,0.56574,\n",
        " 0.56972,0.54980,0.54980,0.52191,0.43426,0.29482,0.13546,0.01594,0.05578,\n",
        " 0.02789,0.00000,0.03187,0.05578,0.07968,0.07570,0.07171,0.06773,0.10757,\n",
        " 0.09562,0.11155,0.09960,0.10359,0.07171,0.05976,0.05179,0.03984,0.01594,\n",
        " 0.02390,0.01195,0.01594,0.00398,0.01992,0.02789,0.05578,0.07968,0.10757,\n",
        " 0.13147,0.16733,0.19124,0.22709,0.24303,0.26693,0.27490,0.29084,0.27888,\n",
        " 0.27888,0.26295,0.25896,0.23506,0.23506,0.22709,0.21514,0.19920,0.20319,\n",
        " 0.19124,0.19124,0.19124,0.20717,0.18725,0.18327,0.17928,0.18327,0.17928,\n",
        " 0.19522,0.18327,0.18725,0.16733,0.16733,0.16335,0.17131,0.15936,0.17131,\n",
        " 0.14343,0.15936,0.13944,0.15936,0.14343,0.15139,0.13546,0.14741,0.13546,\n",
        " 0.15139,0.13546,0.14343,0.12749,0.14741,0.13944,0.14741,0.13944,0.14741,\n",
        " 0.13944,0.14343,0.15139,0.16335,0.17131,0.24701,0.70518,0.84861,0.47809,\n",
        " 0.52191,0.54183,0.55378,0.54183,0.54183,0.49801,0.37052,0.24303,0.08765,\n",
        " 0.11155,0.10757,0.06375,0.06773,0.09960,0.11155,0.09960,0.09163,0.06773,\n",
        " 0.00000,0.00000,0.00000,0.00000,0.00000,0.00000,0.00000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from scipy.signal import find_peaks, butter, filtfilt\n",
        "\n",
        "# def preprocess_ecg_batch_for_prediction(raw_signals, sample_rate=125, output_length=187):\n",
        "#     \"\"\"\n",
        "#     Preprocess multiple raw ECG signals from a sensor to match the format expected by the CNN model.\n",
        "\n",
        "#     Parameters:\n",
        "#     raw_signals (array): Array of raw ECG signals, shape (n_samples, signal_length)\n",
        "#     sample_rate (int): Sampling rate of the ECG signals in Hz\n",
        "#     output_length (int): Required length of the processed signals for the CNN model\n",
        "\n",
        "#     Returns:\n",
        "#     processed_signals (array): Processed signals ready for CNN prediction, shape (n_samples, output_length, 1)\n",
        "#     \"\"\"\n",
        "#     n_samples = len(raw_signals)\n",
        "#     processed_signals = np.zeros((n_samples, output_length, 1))\n",
        "\n",
        "#     for i, raw_signal in enumerate(raw_signals):\n",
        "#         # Apply bandpass filter to remove noise (0.5-40Hz is typical for ECG)\n",
        "#         nyquist = 0.5 * sample_rate\n",
        "#         low = 0.5 / nyquist\n",
        "#         high = 40.0 / nyquist\n",
        "#         b, a = butter(2, [low, high], btype='band')\n",
        "#         filtered_signal = filtfilt(b, a, raw_signal)\n",
        "\n",
        "#         # Normalize the signal\n",
        "#         signal_mean = np.mean(filtered_signal)\n",
        "#         signal_std = np.std(filtered_signal)\n",
        "#         normalized_signal = (filtered_signal - signal_mean) / (signal_std + 1e-10)\n",
        "\n",
        "#         # Find R peaks (the prominent peaks in ECG)\n",
        "#         peaks, _ = find_peaks(normalized_signal, height=0.5, distance=int(sample_rate * 0.5))\n",
        "\n",
        "#         # Initialize the processed signal with zeros\n",
        "#         processed_signal = np.zeros(output_length)\n",
        "\n",
        "#         if len(peaks) >= 2:\n",
        "#             # Get the first two R peaks\n",
        "#             r1, r2 = peaks[0], peaks[1]\n",
        "\n",
        "#             # Calculate beat length\n",
        "#             beat_length = r2 - r1\n",
        "\n",
        "#             # Calculate half beat before first R peak\n",
        "#             half_beat = beat_length // 2\n",
        "#             start_idx = max(0, r1 - half_beat)\n",
        "\n",
        "#             # Extract segment (half beat + full beat)\n",
        "#             end_idx = min(len(normalized_signal), start_idx + beat_length + half_beat)\n",
        "#             segment = normalized_signal[start_idx:end_idx]\n",
        "\n",
        "#             # Place segment at the beginning of the output array\n",
        "#             if len(segment) <= output_length:\n",
        "#                 processed_signal[:len(segment)] = segment\n",
        "#             else:\n",
        "#                 processed_signal = segment[:output_length]\n",
        "\n",
        "#         elif len(peaks) == 1:\n",
        "#             # If only one peak is found, use an estimated beat length\n",
        "#             r1 = peaks[0]\n",
        "#             estimated_beat_length = int(sample_rate * 0.7)  # ~0.7 seconds, typical for heart beat\n",
        "\n",
        "#             # Calculate half beat before R peak\n",
        "#             half_beat = estimated_beat_length // 2\n",
        "#             start_idx = max(0, r1 - half_beat)\n",
        "\n",
        "#             # Extract segment\n",
        "#             end_idx = min(len(normalized_signal), start_idx + estimated_beat_length + half_beat)\n",
        "#             segment = normalized_signal[start_idx:end_idx]\n",
        "\n",
        "#             # Place segment at the beginning of the output array\n",
        "#             if len(segment) <= output_length:\n",
        "#                 processed_signal[:len(segment)] = segment\n",
        "#             else:\n",
        "#                 processed_signal = segment[:output_length]\n",
        "\n",
        "#         else:\n",
        "#             # If no peaks found, use a segment from the beginning\n",
        "#             segment = normalized_signal[:min(output_length, len(normalized_signal))]\n",
        "#             processed_signal[:len(segment)] = segment\n",
        "\n",
        "#         # Add to batch\n",
        "#         processed_signals[i, :, 0] = processed_signal\n",
        "\n",
        "#     return processed_signals\n",
        "\n",
        "# def predict_arrhythmia_batch(raw_signals, model, class_names=None):\n",
        "#     \"\"\"\n",
        "#     Process multiple raw ECG signals and predict the arrhythmia class for each.\n",
        "\n",
        "#     Parameters:\n",
        "#     raw_signals (array): Array of raw ECG signals\n",
        "#     model: Loaded Keras CNN model\n",
        "#     class_names (list): Names of the arrhythmia classes\n",
        "\n",
        "#     Returns:\n",
        "#     predicted_classes (array): Predicted class indices\n",
        "#     class_names (array): Names of the predicted classes\n",
        "#     confidences (array): Confidence scores for the predictions\n",
        "#     \"\"\"\n",
        "#     if class_names is None:\n",
        "#         class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "\n",
        "#     # Preprocess the signals\n",
        "#     processed_signals = preprocess_ecg_batch_for_prediction(raw_signals)\n",
        "\n",
        "#     # Make predictions\n",
        "#     predictions = model.predict(processed_signals)\n",
        "#     predicted_classes = np.argmax(predictions, axis=1)\n",
        "#     confidences = np.max(predictions, axis=1)\n",
        "\n",
        "#     # Get class names\n",
        "#     predicted_class_names = [class_names[idx] for idx in predicted_classes]\n",
        "\n",
        "#     return predicted_classes, predicted_class_names, confidences"
      ],
      "metadata": {
        "id": "T75Jjx1i32W5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rvxMCLn_33JE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Bvq85lw4Icb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_ecg_batch_for_prediction(raw_signals, sample_rate=125, output_length=187):\n",
        "    \"\"\"\n",
        "    Preprocess multiple raw ECG signals for prediction.\n",
        "    \"\"\"\n",
        "    # Convert to numpy array if not already\n",
        "    raw_signals = np.array(raw_signals)\n",
        "\n",
        "    # Check if input is 1D, and reshape to 2D if needed\n",
        "    if raw_signals.ndim == 1:\n",
        "        raw_signals = np.array([raw_signals])\n",
        "\n",
        "    n_samples = len(raw_signals)\n",
        "    processed_signals = np.zeros((n_samples, output_length, 1))\n",
        "\n",
        "    for i, raw_signal in enumerate(raw_signals):\n",
        "        # Skip filtering for very short signals or if filtering fails\n",
        "        try:\n",
        "            # Apply bandpass filter\n",
        "            nyquist = 0.5 * sample_rate\n",
        "            low = 0.5 / nyquist\n",
        "            high = 40.0 / nyquist\n",
        "            b, a = butter(2, [low, high], btype='band')\n",
        "\n",
        "            # Check if signal is long enough for filtfilt (needs length > 3 * (max(len(a), len(b)) - 1))\n",
        "            min_length = 3 * (max(len(a), len(b)) - 1)\n",
        "            if len(raw_signal) > min_length:\n",
        "                filtered_signal = filtfilt(b, a, raw_signal)\n",
        "            else:\n",
        "                filtered_signal = raw_signal  # Use raw signal if too short\n",
        "        except Exception as e:\n",
        "            print(f\"Filtering failed for signal {i}: {e}\")\n",
        "            filtered_signal = raw_signal\n",
        "\n",
        "        # Normalize the signal\n",
        "        signal_mean = np.mean(filtered_signal)\n",
        "        signal_std = np.std(filtered_signal)\n",
        "        if signal_std > 1e-10:  # Avoid division by zero\n",
        "            normalized_signal = (filtered_signal - signal_mean) / signal_std\n",
        "        else:\n",
        "            normalized_signal = filtered_signal - signal_mean\n",
        "\n",
        "        # Rest of your code remains the same...\n",
        "        # Find R peaks (the prominent peaks in ECG)\n",
        "        peaks, _ = find_peaks(normalized_signal, height=0.5, distance=int(sample_rate * 0.5))\n",
        "\n",
        "        # Initialize the processed signal with zeros\n",
        "        processed_signal = np.zeros(output_length)\n",
        "\n",
        "        if len(peaks) >= 2:\n",
        "            # Get the first two R peaks\n",
        "            r1, r2 = peaks[0], peaks[1]\n",
        "\n",
        "            # Calculate beat length\n",
        "            beat_length = r2 - r1\n",
        "\n",
        "            # Calculate half beat before first R peak\n",
        "            half_beat = beat_length // 2\n",
        "            start_idx = max(0, r1 - half_beat)\n",
        "\n",
        "            # Extract segment (half beat + full beat)\n",
        "            end_idx = min(len(normalized_signal), start_idx + beat_length + half_beat)\n",
        "            segment = normalized_signal[start_idx:end_idx]\n",
        "\n",
        "            # Place segment at the beginning of the output array\n",
        "            if len(segment) <= output_length:\n",
        "                processed_signal[:len(segment)] = segment\n",
        "            else:\n",
        "                processed_signal = segment[:output_length]\n",
        "\n",
        "        elif len(peaks) == 1:\n",
        "            # If only one peak is found, use an estimated beat length\n",
        "            r1 = peaks[0]\n",
        "            estimated_beat_length = int(sample_rate * 0.7)  # ~0.7 seconds, typical for heart beat\n",
        "\n",
        "            # Calculate half beat before R peak\n",
        "            half_beat = estimated_beat_length // 2\n",
        "            start_idx = max(0, r1 - half_beat)\n",
        "\n",
        "            # Extract segment\n",
        "            end_idx = min(len(normalized_signal), start_idx + estimated_beat_length + half_beat)\n",
        "            segment = normalized_signal[start_idx:end_idx]\n",
        "\n",
        "            # Place segment at the beginning of the output array\n",
        "            if len(segment) <= output_length:\n",
        "                processed_signal[:len(segment)] = segment\n",
        "            else:\n",
        "                processed_signal = segment[:output_length]\n",
        "\n",
        "        else:\n",
        "            # If no peaks found, use a segment from the beginning\n",
        "            segment = normalized_signal[:min(output_length, len(normalized_signal))]\n",
        "            processed_signal[:len(segment)] = segment\n",
        "\n",
        "        # Add to batch\n",
        "        processed_signals[i, :, 0] = processed_signal\n",
        "\n",
        "    return processed_signals\n",
        "\n",
        "def predict_arrhythmia_batch(raw_signals, model, class_names=None):\n",
        "    \"\"\"\n",
        "    Process multiple raw ECG signals and predict the arrhythmia class for each.\n",
        "\n",
        "    Parameters:\n",
        "    raw_signals (array): Array of raw ECG signals\n",
        "    model: Loaded Keras CNN model\n",
        "    class_names (list): Names of the arrhythmia classes\n",
        "\n",
        "    Returns:\n",
        "    predicted_classes (array): Predicted class indices\n",
        "    class_names (array): Names of the predicted classes\n",
        "    confidences (array): Confidence scores for the predictions\n",
        "    \"\"\"\n",
        "    if class_names is None:\n",
        "        class_names = ['Normal', 'Supraventricular', 'Ventricular', 'Fusion', 'Unknown']\n",
        "\n",
        "    # Preprocess the signals\n",
        "    processed_signals = preprocess_ecg_batch_for_prediction(raw_signals)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(processed_signals)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    confidences = np.max(predictions, axis=1)\n",
        "\n",
        "    # Get class names\n",
        "    predicted_class_names = [class_names[idx] for idx in predicted_classes]\n",
        "\n",
        "    return predicted_classes, predicted_class_names, confidences"
      ],
      "metadata": {
        "id": "8YRJxbcM9HRQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from scipy.signal import find_peaks, butter, filtfilt\n",
        "\n",
        "# Load your trained model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('claude2_ecg_detection_model.keras')\n",
        "\n",
        "\n",
        "# Use the X variable that contains your ECG data\n",
        "# First, we need to format it appropriately since it looks like it has 3 signals concatenated\n",
        "signal_length = 187  # Based on the plot and your comment\n",
        "signals = []\n",
        "\n",
        "# Split the X array into 3 separate signals (assuming they are contiguous)\n",
        "for i in range(0, len(X), signal_length):\n",
        "    if i + signal_length <= len(X):\n",
        "        signals.append(X[i:i+signal_length])\n",
        "    else:\n",
        "        # Handle the last segment if it's not complete\n",
        "        last_signal = X[i:]\n",
        "        # Pad with zeros if needed\n",
        "        if len(last_signal) < signal_length:\n",
        "            last_signal = np.pad(last_signal, (0, signal_length - len(last_signal)))\n",
        "        signals.append(last_signal)\n",
        "\n",
        "# Convert to numpy array\n",
        "raw_ecg_data = np.array(signals)\n",
        "\n",
        "# Now we can proceed with prediction\n",
        "class_indices, class_names, confidences = predict_arrhythmia_batch(raw_ecg_data, model)\n",
        "\n",
        "# Display results for each signal\n",
        "for i, (class_idx, class_name, confidence) in enumerate(zip(class_indices, class_names, confidences)):\n",
        "    print(f\"Signal {i+1}: Predicted {class_name} with {confidence*100:.2f}% confidence\")"
      ],
      "metadata": {
        "id": "xQ_uMZPG94Qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829dc28d-f8a3-4565-b7bf-61b763a0de8e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Signal 1: Predicted Normal with 90.12% confidence\n",
            "Signal 2: Predicted Ventricular with 99.57% confidence\n",
            "Signal 3: Predicted Normal with 99.60% confidence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TILTFe9XRIbt"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}